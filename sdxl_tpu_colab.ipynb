{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "TPU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion XL on TPU\n",
        "\n",
        "This notebook runs SDXL image generation directly on Google Colab's TPU using JAX/Flax.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Set Runtime to TPU**: Go to `Runtime` > `Change runtime type` > Select `TPU` > `Save`\n",
        "2. **Run all cells**: Click `Runtime` > `Run all`\n",
        "3. **Wait for warmup**: The first compilation takes ~3 minutes\n",
        "4. **Generate images**: Use the Gradio interface that appears\n",
        "\n",
        "The model generates 8 images in parallel across the 8 TPU cores."
      ],
      "metadata": {
        "id": "title-cell"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify TPU is available\n",
        "import os\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    print(f\"TPU available at: {os.environ['COLAB_TPU_ADDR']}\")\n",
        "else:\n",
        "    raise RuntimeError(\n",
        "        \"TPU not found! Please go to Runtime > Change runtime type > \"\n",
        "        \"Select 'TPU' and restart the notebook.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "tpu-verification"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip install -q diffusers transformers flax gradio"
      ],
      "metadata": {
        "id": "pip-installs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import pmap\n",
        "from flax.jax_utils import replicate, unreplicate\n",
        "from diffusers import FlaxStableDiffusionXLPipeline\n",
        "import gradio as gr\n",
        "from typing import Tuple\n",
        "import time\n",
        "\n",
        "# Verify JAX sees TPU devices\n",
        "devices = jax.devices()\n",
        "print(f\"JAX devices: {len(devices)} TPU cores\")\n",
        "for d in devices:\n",
        "    print(f\"  - {d}\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Style system\n",
        "style_list = [\n",
        "    {\n",
        "        \"name\": \"(No style)\",\n",
        "        \"prompt\": \"{prompt}\",\n",
        "        \"negative_prompt\": \"\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Cinematic\",\n",
        "        \"prompt\": \"cinematic still {prompt} . emotional, harmonious, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n",
        "        \"negative_prompt\": \"anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Photographic\",\n",
        "        \"prompt\": \"cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\",\n",
        "        \"negative_prompt\": \"drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Anime\",\n",
        "        \"prompt\": \"anime artwork {prompt} . anime style, key visual, vibrant, studio anime, highly detailed\",\n",
        "        \"negative_prompt\": \"photo, deformed, black and white, realism, disfigured, low contrast\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Manga\",\n",
        "        \"prompt\": \"manga style {prompt} . vibrant, high-energy, detailed, iconic, Japanese comic style\",\n",
        "        \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, Western comic style\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Digital Art\",\n",
        "        \"prompt\": \"concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed\",\n",
        "        \"negative_prompt\": \"photo, photorealistic, realism, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Pixel art\",\n",
        "        \"prompt\": \"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics\",\n",
        "        \"negative_prompt\": \"sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Fantasy art\",\n",
        "        \"prompt\": \"ethereal fantasy concept art of {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\",\n",
        "        \"negative_prompt\": \"photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Neonpunk\",\n",
        "        \"prompt\": \"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n",
        "        \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"3D Model\",\n",
        "        \"prompt\": \"professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting\",\n",
        "        \"negative_prompt\": \"ugly, deformed, noisy, low poly, blurry, painting\",\n",
        "    },\n",
        "]\n",
        "\n",
        "styles = {k[\"name\"]: (k[\"prompt\"], k[\"negative_prompt\"]) for k in style_list}\n",
        "STYLE_NAMES = list(styles.keys())\n",
        "DEFAULT_STYLE_NAME = \"(No style)\"\n",
        "\n",
        "\n",
        "def apply_style(style_name: str, positive: str, negative: str = \"\") -> Tuple[str, str]:\n",
        "    p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
        "    return p.replace(\"{prompt}\", positive), n + negative\n",
        "\n",
        "print(f\"Loaded {len(style_list)} styles\")"
      ],
      "metadata": {
        "id": "style-system"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with bfloat16 for TPU efficiency\n",
        "print(\"Loading SDXL model (this may take a few minutes)...\")\n",
        "\n",
        "pipeline, params = FlaxStableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    split_head_dim=True,  # TPU optimization\n",
        "    dtype=jnp.bfloat16,\n",
        ")\n",
        "\n",
        "# Keep scheduler params in float32 for numerical stability\n",
        "scheduler_state = params.pop(\"scheduler\")\n",
        "params = jax.tree_util.tree_map(lambda x: x.astype(jnp.bfloat16), params)\n",
        "params[\"scheduler\"] = scheduler_state\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "id": "model-loading"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replicate params across all TPU cores for parallel generation\n",
        "num_devices = jax.local_device_count()\n",
        "print(f\"Replicating model across {num_devices} TPU cores...\")\n",
        "\n",
        "p_params = replicate(params)\n",
        "\n",
        "print(\"Model replicated!\")"
      ],
      "metadata": {
        "id": "parallelization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def tokenize_prompt(prompt: str, negative_prompt: str):\n",
        "    \"\"\"Tokenize prompts and replicate across devices.\"\"\"\n",
        "    prompt_ids = pipeline.prepare_inputs(prompt)\n",
        "    neg_prompt_ids = pipeline.prepare_inputs(negative_prompt)\n",
        "    return prompt_ids, neg_prompt_ids\n",
        "\n",
        "\n",
        "def generate_images(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"low quality\",\n",
        "    guidance_scale: float = 7.5,\n",
        "    style_name: str = \"(No style)\",\n",
        "    num_steps: int = 30,\n",
        "    seed: int = None,\n",
        "    num_images: int = 4,\n",
        "):\n",
        "    \"\"\"Generate images using SDXL on TPU.\"\"\"\n",
        "    # Apply style\n",
        "    styled_prompt, styled_negative = apply_style(style_name, prompt, negative_prompt)\n",
        "    \n",
        "    # Tokenize\n",
        "    prompt_ids, neg_prompt_ids = tokenize_prompt(styled_prompt, styled_negative)\n",
        "    \n",
        "    # Replicate inputs across devices\n",
        "    prompt_ids = replicate(prompt_ids)\n",
        "    neg_prompt_ids = replicate(neg_prompt_ids)\n",
        "    \n",
        "    # Create different random seeds for each device\n",
        "    if seed is None:\n",
        "        seed = int(time.time())\n",
        "    \n",
        "    # Create PRNGKeys - one per device for parallel generation\n",
        "    rng = jax.random.PRNGKey(seed)\n",
        "    rngs = jax.random.split(rng, num_devices)\n",
        "    \n",
        "    # Generate images\n",
        "    start_time = time.time()\n",
        "    images = pipeline(\n",
        "        prompt_ids=prompt_ids,\n",
        "        params=p_params,\n",
        "        prng_seed=rngs,\n",
        "        num_inference_steps=num_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        neg_prompt_ids=neg_prompt_ids,\n",
        "        jit=True,\n",
        "    ).images\n",
        "    \n",
        "    # Block until computation is done\n",
        "    images = images.block_until_ready()\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Generated {num_devices} images in {elapsed:.2f}s\")\n",
        "    \n",
        "    # Convert to PIL images\n",
        "    images = images.reshape((num_devices, images.shape[-3], images.shape[-2], images.shape[-1]))\n",
        "    pil_images = pipeline.numpy_to_pil(jax.device_get(images))\n",
        "    \n",
        "    # Return requested number of images\n",
        "    return pil_images[:num_images]\n",
        "\n",
        "print(\"Inference function defined.\")"
      ],
      "metadata": {
        "id": "inference-function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warmup - trigger JIT compilation before UI\n",
        "print(\"Running warmup to compile model (this takes ~3 minutes)...\")\n",
        "print(\"Subsequent generations will be much faster.\")\n",
        "\n",
        "warmup_start = time.time()\n",
        "_ = generate_images(\n",
        "    prompt=\"a photo of a cat\",\n",
        "    num_images=1,\n",
        ")\n",
        "warmup_elapsed = time.time() - warmup_start\n",
        "print(f\"\\nWarmup complete in {warmup_elapsed:.1f}s. Model is ready!\")"
      ],
      "metadata": {
        "id": "warmup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "def infer(prompt, negative_prompt, guidance_scale, style_name, num_images):\n",
        "    \"\"\"Gradio inference wrapper.\"\"\"\n",
        "    if not prompt:\n",
        "        raise gr.Error(\"Please enter a prompt\")\n",
        "    \n",
        "    images = generate_images(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt or \"low quality\",\n",
        "        guidance_scale=guidance_scale,\n",
        "        style_name=style_name,\n",
        "        num_images=int(num_images),\n",
        "    )\n",
        "    return images\n",
        "\n",
        "\n",
        "# CSS for styling\n",
        "css = \"\"\"\n",
        ".gradio-container {\n",
        "    font-family: 'IBM Plex Sans', sans-serif;\n",
        "    max-width: 730px !important;\n",
        "    margin: auto;\n",
        "    padding-top: 1.5rem;\n",
        "}\n",
        ".gr-button {\n",
        "    color: white;\n",
        "    border-color: black;\n",
        "    background: black;\n",
        "}\n",
        "#gallery {\n",
        "    min-height: 22rem;\n",
        "    margin-bottom: 15px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Example prompts\n",
        "examples = [\n",
        "    [\"A serious capybara at work, wearing a suit\"],\n",
        "    [\"A Squirtle fine dining with a view to the London Eye\"],\n",
        "    [\"A tamale food cart in front of a Japanese Castle\"],\n",
        "    [\"a graffiti of a robot serving meals to people\"],\n",
        "    [\"a beautiful cabin in Attersee, Austria, 3d animation style\"],\n",
        "]\n",
        "\n",
        "# Build interface\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "        <div style=\"text-align: center; margin: 0 auto;\">\n",
        "            <h1 style=\"font-weight: 900; margin-bottom: 7px; margin-top: 5px\">\n",
        "                Stable Diffusion XL on TPU\n",
        "            </h1>\n",
        "            <p style=\"margin-bottom: 10px; font-size: 94%; line-height: 23px;\">\n",
        "                SDXL running on Google Colab TPU with JAX/Flax.\n",
        "                Generates up to 8 images in parallel across TPU cores.\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(\n",
        "            label=\"Prompt\",\n",
        "            placeholder=\"Enter your prompt\",\n",
        "            max_lines=1,\n",
        "        )\n",
        "        btn = gr.Button(\"Generate\", scale=0)\n",
        "    \n",
        "    gallery = gr.Gallery(\n",
        "        label=\"Generated images\",\n",
        "        elem_id=\"gallery\",\n",
        "        columns=2,\n",
        "        height=\"auto\",\n",
        "    )\n",
        "    \n",
        "    with gr.Accordion(\"Advanced settings\", open=False):\n",
        "        style_selection = gr.Radio(\n",
        "            choices=STYLE_NAMES,\n",
        "            value=DEFAULT_STYLE_NAME,\n",
        "            label=\"Image Style\",\n",
        "        )\n",
        "        negative = gr.Textbox(\n",
        "            label=\"Negative prompt\",\n",
        "            placeholder=\"Enter a negative prompt\",\n",
        "            max_lines=1,\n",
        "        )\n",
        "        guidance_scale = gr.Slider(\n",
        "            label=\"Guidance Scale\",\n",
        "            minimum=0,\n",
        "            maximum=50,\n",
        "            value=7.5,\n",
        "            step=0.1,\n",
        "        )\n",
        "        num_images = gr.Slider(\n",
        "            label=\"Number of images\",\n",
        "            minimum=1,\n",
        "            maximum=8,\n",
        "            value=4,\n",
        "            step=1,\n",
        "        )\n",
        "    \n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=[prompt],\n",
        "    )\n",
        "    \n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "        <div style=\"text-align: center; margin-top: 20px; font-size: 0.8rem; color: #666;\">\n",
        "            <p>Model: <a href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\" target=\"_blank\">stabilityai/stable-diffusion-xl-base-1.0</a></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    # Event handlers\n",
        "    btn.click(\n",
        "        infer,\n",
        "        inputs=[prompt, negative, guidance_scale, style_selection, num_images],\n",
        "        outputs=[gallery],\n",
        "    )\n",
        "    prompt.submit(\n",
        "        infer,\n",
        "        inputs=[prompt, negative, guidance_scale, style_selection, num_images],\n",
        "        outputs=[gallery],\n",
        "    )\n",
        "\n",
        "print(\"Gradio interface built.\")"
      ],
      "metadata": {
        "id": "gradio-ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the app with a public URL\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "launch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
