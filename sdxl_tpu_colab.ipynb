{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion XL on Colab\n",
        "\n",
        "This notebook runs SDXL image generation on Google Colab using either **TPU** (JAX/Flax) or **GPU** (PyTorch).\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Choose your runtime**: Go to `Runtime` > `Change runtime type`\n",
        "   - **TPU**: Generates 8 images in parallel across TPU cores (JAX/Flax)\n",
        "   - **GPU (T4)**: Generates 1 image at a time (PyTorch, fp16)\n",
        "2. **Configure storage** (optional): Toggle `use_google_drive` in the next cell\n",
        "   - **On**: Caches model to Google Drive (~6.5GB), faster on future runs\n",
        "   - **Off**: Downloads model each session, no Drive access needed\n",
        "3. **Run all cells**: Click `Runtime` > `Run all`\n",
        "4. **Generate images**: Use the Gradio interface that appears"
      ],
      "metadata": {
        "id": "title-cell"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration { display-mode: \"form\" }\n",
        "# @markdown ### Storage Settings\n",
        "# @markdown Toggle Google Drive for model caching and image saving:\n",
        "\n",
        "use_google_drive = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **With Google Drive:**\n",
        "# @markdown - Model cached for faster future runs\n",
        "# @markdown - Can save generated images to Drive\n",
        "# @markdown \n",
        "# @markdown **Without Google Drive:**\n",
        "# @markdown - Model downloaded each session\n",
        "# @markdown - No authorization required\n",
        "\n",
        "import os\n",
        "\n",
        "USE_GOOGLE_DRIVE = use_google_drive\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Set up cache directory on Google Drive\n",
        "    CACHE_DIR = '/content/drive/MyDrive/.cache/huggingface'\n",
        "    OUTPUT_DIR = '/content/drive/MyDrive/sdxl_outputs'\n",
        "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    \n",
        "    # Set environment variables for Hugging Face cache\n",
        "    os.environ['HF_HOME'] = CACHE_DIR\n",
        "    os.environ['TRANSFORMERS_CACHE'] = CACHE_DIR\n",
        "    os.environ['HF_DATASETS_CACHE'] = CACHE_DIR\n",
        "    \n",
        "    print(f\"\\nCache directory: {CACHE_DIR}\")\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "    \n",
        "    # Check if model is already cached\n",
        "    model_cache_path = os.path.join(CACHE_DIR, 'hub', 'models--stabilityai--stable-diffusion-xl-base-1.0')\n",
        "    if os.path.exists(model_cache_path):\n",
        "        print(\"\\nSDXL model found in cache - loading will be fast!\")\n",
        "    else:\n",
        "        print(\"\\nSDXL model not cached yet - first run will download ~6.5GB\")\n",
        "else:\n",
        "    # Use default local cache (lost when session ends)\n",
        "    CACHE_DIR = '/root/.cache/huggingface'\n",
        "    OUTPUT_DIR = '/content/outputs'\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    \n",
        "    print(\"Google Drive disabled.\")\n",
        "    print(\"Model will be downloaded each session (~6.5GB).\")\n",
        "    print(f\"\\nOutput directory: {OUTPUT_DIR} (local, lost when session ends)\")"
      ],
      "metadata": {
        "id": "config-storage"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect runtime type (TPU vs GPU)\n",
        "import subprocess\n",
        "\n",
        "USE_TPU = 'COLAB_TPU_ADDR' in os.environ\n",
        "\n",
        "if USE_TPU:\n",
        "    print(f\"TPU detected at: {os.environ['COLAB_TPU_ADDR']}\")\n",
        "    print(\"Using JAX/Flax backend for parallel generation across 8 TPU cores.\")\n",
        "    RUNTIME = \"TPU\"\n",
        "else:\n",
        "    # Check for GPU\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],\n",
        "                                capture_output=True, text=True)\n",
        "        gpu_name = result.stdout.strip()\n",
        "        if gpu_name:\n",
        "            print(f\"GPU detected: {gpu_name}\")\n",
        "            print(\"Using PyTorch backend with fp16.\")\n",
        "            RUNTIME = \"GPU\"\n",
        "        else:\n",
        "            raise RuntimeError(\"No GPU found\")\n",
        "    except Exception:\n",
        "        raise RuntimeError(\n",
        "            \"No TPU or GPU found! Please go to Runtime > Change runtime type > \"\n",
        "            \"Select 'TPU' or 'GPU' and restart the notebook.\"\n",
        "        )\n",
        "\n",
        "print(f\"\\nRuntime: {RUNTIME}\")"
      ],
      "metadata": {
        "id": "runtime-detection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies based on runtime\n",
        "if USE_TPU:\n",
        "    !pip install -q jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "    !pip install -q diffusers transformers flax gradio\n",
        "else:\n",
        "    !pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "    !pip install -q diffusers transformers accelerate gradio"
      ],
      "metadata": {
        "id": "pip-installs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import gradio as gr\n",
        "from typing import Tuple\n",
        "import time\n",
        "\n",
        "if USE_TPU:\n",
        "    import jax\n",
        "    import jax.numpy as jnp\n",
        "    from flax.jax_utils import replicate\n",
        "    from diffusers import FlaxStableDiffusionXLPipeline\n",
        "    \n",
        "    devices = jax.devices()\n",
        "    NUM_DEVICES = len(devices)\n",
        "    print(f\"JAX devices: {NUM_DEVICES} TPU cores\")\n",
        "    for d in devices:\n",
        "        print(f\"  - {d}\")\n",
        "else:\n",
        "    import torch\n",
        "    from diffusers import StableDiffusionXLPipeline\n",
        "    \n",
        "    NUM_DEVICES = 1\n",
        "    print(f\"PyTorch device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Style system\n",
        "style_list = [\n",
        "    {\n",
        "        \"name\": \"(No style)\",\n",
        "        \"prompt\": \"{prompt}\",\n",
        "        \"negative_prompt\": \"\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Cinematic\",\n",
        "        \"prompt\": \"cinematic still {prompt} . emotional, harmonious, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n",
        "        \"negative_prompt\": \"anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Photographic\",\n",
        "        \"prompt\": \"cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\",\n",
        "        \"negative_prompt\": \"drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Anime\",\n",
        "        \"prompt\": \"anime artwork {prompt} . anime style, key visual, vibrant, studio anime, highly detailed\",\n",
        "        \"negative_prompt\": \"photo, deformed, black and white, realism, disfigured, low contrast\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Manga\",\n",
        "        \"prompt\": \"manga style {prompt} . vibrant, high-energy, detailed, iconic, Japanese comic style\",\n",
        "        \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, Western comic style\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Digital Art\",\n",
        "        \"prompt\": \"concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed\",\n",
        "        \"negative_prompt\": \"photo, photorealistic, realism, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Pixel art\",\n",
        "        \"prompt\": \"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics\",\n",
        "        \"negative_prompt\": \"sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Fantasy art\",\n",
        "        \"prompt\": \"ethereal fantasy concept art of {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\",\n",
        "        \"negative_prompt\": \"photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Neonpunk\",\n",
        "        \"prompt\": \"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n",
        "        \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"3D Model\",\n",
        "        \"prompt\": \"professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting\",\n",
        "        \"negative_prompt\": \"ugly, deformed, noisy, low poly, blurry, painting\",\n",
        "    },\n",
        "]\n",
        "\n",
        "styles = {k[\"name\"]: (k[\"prompt\"], k[\"negative_prompt\"]) for k in style_list}\n",
        "STYLE_NAMES = list(styles.keys())\n",
        "DEFAULT_STYLE_NAME = \"(No style)\"\n",
        "\n",
        "\n",
        "def apply_style(style_name: str, positive: str, negative: str = \"\") -> Tuple[str, str]:\n",
        "    p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
        "    return p.replace(\"{prompt}\", positive), n + negative\n",
        "\n",
        "print(f\"Loaded {len(style_list)} styles\")"
      ],
      "metadata": {
        "id": "style-system"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "print(\"Loading SDXL model...\")\n",
        "print(f\"Cache directory: {CACHE_DIR}\")\n",
        "\n",
        "load_start = time.time()\n",
        "\n",
        "if USE_TPU:\n",
        "    # JAX/Flax pipeline for TPU\n",
        "    pipeline, params = FlaxStableDiffusionXLPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        split_head_dim=True,  # TPU optimization\n",
        "        dtype=jnp.bfloat16,\n",
        "        cache_dir=CACHE_DIR,\n",
        "    )\n",
        "    \n",
        "    # Keep scheduler params in float32 for numerical stability\n",
        "    scheduler_state = params.pop(\"scheduler\")\n",
        "    params = jax.tree_util.tree_map(lambda x: x.astype(jnp.bfloat16), params)\n",
        "    params[\"scheduler\"] = scheduler_state\n",
        "    \n",
        "    # Replicate across TPU cores\n",
        "    print(f\"Replicating model across {NUM_DEVICES} TPU cores...\")\n",
        "    p_params = replicate(params)\n",
        "    \n",
        "else:\n",
        "    # PyTorch pipeline for GPU\n",
        "    pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\",\n",
        "        use_safetensors=True,\n",
        "        cache_dir=CACHE_DIR,\n",
        "    )\n",
        "    pipeline = pipeline.to(\"cuda\")\n",
        "    \n",
        "    # Enable memory optimizations for T4\n",
        "    pipeline.enable_attention_slicing()\n",
        "\n",
        "load_elapsed = time.time() - load_start\n",
        "print(f\"\\nModel loaded in {load_elapsed:.1f}s\")"
      ],
      "metadata": {
        "id": "model-loading"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "if USE_TPU:\n",
        "    def generate_images(\n",
        "        prompt: str,\n",
        "        negative_prompt: str = \"low quality\",\n",
        "        guidance_scale: float = 7.5,\n",
        "        style_name: str = \"(No style)\",\n",
        "        num_steps: int = 30,\n",
        "        seed: int = None,\n",
        "        num_images: int = 4,\n",
        "    ):\n",
        "        \"\"\"Generate images using SDXL on TPU.\"\"\"\n",
        "        styled_prompt, styled_negative = apply_style(style_name, prompt, negative_prompt)\n",
        "        \n",
        "        prompt_ids = pipeline.prepare_inputs(styled_prompt)\n",
        "        neg_prompt_ids = pipeline.prepare_inputs(styled_negative)\n",
        "        \n",
        "        prompt_ids = replicate(prompt_ids)\n",
        "        neg_prompt_ids = replicate(neg_prompt_ids)\n",
        "        \n",
        "        if seed is None:\n",
        "            seed = int(time.time())\n",
        "        \n",
        "        rng = jax.random.PRNGKey(seed)\n",
        "        rngs = jax.random.split(rng, NUM_DEVICES)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        images = pipeline(\n",
        "            prompt_ids=prompt_ids,\n",
        "            params=p_params,\n",
        "            prng_seed=rngs,\n",
        "            num_inference_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            neg_prompt_ids=neg_prompt_ids,\n",
        "            jit=True,\n",
        "        ).images\n",
        "        \n",
        "        images = images.block_until_ready()\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Generated {NUM_DEVICES} images in {elapsed:.2f}s\")\n",
        "        \n",
        "        images = images.reshape((NUM_DEVICES, images.shape[-3], images.shape[-2], images.shape[-1]))\n",
        "        pil_images = pipeline.numpy_to_pil(jax.device_get(images))\n",
        "        \n",
        "        return pil_images[:num_images]\n",
        "\n",
        "else:\n",
        "    def generate_images(\n",
        "        prompt: str,\n",
        "        negative_prompt: str = \"low quality\",\n",
        "        guidance_scale: float = 7.5,\n",
        "        style_name: str = \"(No style)\",\n",
        "        num_steps: int = 30,\n",
        "        seed: int = None,\n",
        "        num_images: int = 1,\n",
        "    ):\n",
        "        \"\"\"Generate images using SDXL on GPU.\"\"\"\n",
        "        styled_prompt, styled_negative = apply_style(style_name, prompt, negative_prompt)\n",
        "        \n",
        "        if seed is None:\n",
        "            seed = int(time.time())\n",
        "        \n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "        \n",
        "        pil_images = []\n",
        "        start_time = time.time()\n",
        "        \n",
        "        for i in range(num_images):\n",
        "            image = pipeline(\n",
        "                prompt=styled_prompt,\n",
        "                negative_prompt=styled_negative,\n",
        "                guidance_scale=guidance_scale,\n",
        "                num_inference_steps=num_steps,\n",
        "                generator=generator,\n",
        "            ).images[0]\n",
        "            pil_images.append(image)\n",
        "            \n",
        "            # Different seed for next image\n",
        "            generator = torch.Generator(device=\"cuda\").manual_seed(seed + i + 1)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Generated {num_images} image(s) in {elapsed:.2f}s\")\n",
        "        \n",
        "        return pil_images\n",
        "\n",
        "print(\"Inference function defined.\")"
      ],
      "metadata": {
        "id": "inference-function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warmup - trigger compilation/loading before UI\n",
        "print(\"Running warmup...\")\n",
        "if USE_TPU:\n",
        "    print(\"(JIT compilation on TPU takes ~3 minutes, subsequent runs are fast)\")\n",
        "\n",
        "warmup_start = time.time()\n",
        "_ = generate_images(\n",
        "    prompt=\"a photo of a cat\",\n",
        "    num_images=1,\n",
        ")\n",
        "warmup_elapsed = time.time() - warmup_start\n",
        "print(f\"\\nWarmup complete in {warmup_elapsed:.1f}s. Model is ready!\")"
      ],
      "metadata": {
        "id": "warmup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "MAX_IMAGES = 8 if USE_TPU else 4  # GPU generates sequentially, so limit to 4\n",
        "\n",
        "def infer(prompt, negative_prompt, guidance_scale, style_name, num_images, save_images):\n",
        "    \"\"\"Gradio inference wrapper.\"\"\"\n",
        "    if not prompt:\n",
        "        raise gr.Error(\"Please enter a prompt\")\n",
        "    \n",
        "    images = generate_images(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt or \"low quality\",\n",
        "        guidance_scale=guidance_scale,\n",
        "        style_name=style_name,\n",
        "        num_images=int(num_images),\n",
        "    )\n",
        "    \n",
        "    # Save images if requested\n",
        "    if save_images:\n",
        "        timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
        "        for i, img in enumerate(images):\n",
        "            safe_prompt = prompt[:50].replace(' ', '_').replace('/', '_')\n",
        "            filename = f\"{timestamp}_{safe_prompt}_{i}.png\"\n",
        "            filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "            img.save(filepath)\n",
        "        print(f\"Saved {len(images)} image(s) to {OUTPUT_DIR}\")\n",
        "    \n",
        "    return images\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        ".gradio-container {\n",
        "    font-family: 'IBM Plex Sans', sans-serif;\n",
        "    max-width: 730px !important;\n",
        "    margin: auto;\n",
        "    padding-top: 1.5rem;\n",
        "}\n",
        ".gr-button {\n",
        "    color: white;\n",
        "    border-color: black;\n",
        "    background: black;\n",
        "}\n",
        "#gallery {\n",
        "    min-height: 22rem;\n",
        "    margin-bottom: 15px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "examples = [\n",
        "    [\"A serious capybara at work, wearing a suit\"],\n",
        "    [\"A Squirtle fine dining with a view to the London Eye\"],\n",
        "    [\"A tamale food cart in front of a Japanese Castle\"],\n",
        "    [\"a graffiti of a robot serving meals to people\"],\n",
        "    [\"a beautiful cabin in Attersee, Austria, 3d animation style\"],\n",
        "]\n",
        "\n",
        "runtime_info = f\"Running on **{RUNTIME}** ({'JAX/Flax, 8 parallel images' if USE_TPU else 'PyTorch fp16'})\"\n",
        "storage_info = \"Google Drive\" if USE_GOOGLE_DRIVE else \"Local (session only)\"\n",
        "\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.HTML(\n",
        "        f\"\"\"\n",
        "        <div style=\"text-align: center; margin: 0 auto;\">\n",
        "            <h1 style=\"font-weight: 900; margin-bottom: 7px; margin-top: 5px\">\n",
        "                Stable Diffusion XL on Colab\n",
        "            </h1>\n",
        "            <p style=\"margin-bottom: 10px; font-size: 94%; line-height: 23px;\">\n",
        "                {runtime_info} | Storage: {storage_info}\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(\n",
        "            label=\"Prompt\",\n",
        "            placeholder=\"Enter your prompt\",\n",
        "            max_lines=1,\n",
        "        )\n",
        "        btn = gr.Button(\"Generate\", scale=0)\n",
        "    \n",
        "    gallery = gr.Gallery(\n",
        "        label=\"Generated images\",\n",
        "        elem_id=\"gallery\",\n",
        "        columns=2,\n",
        "        height=\"auto\",\n",
        "    )\n",
        "    \n",
        "    with gr.Accordion(\"Advanced settings\", open=False):\n",
        "        style_selection = gr.Radio(\n",
        "            choices=STYLE_NAMES,\n",
        "            value=DEFAULT_STYLE_NAME,\n",
        "            label=\"Image Style\",\n",
        "        )\n",
        "        negative = gr.Textbox(\n",
        "            label=\"Negative prompt\",\n",
        "            placeholder=\"Enter a negative prompt\",\n",
        "            max_lines=1,\n",
        "        )\n",
        "        guidance_scale = gr.Slider(\n",
        "            label=\"Guidance Scale\",\n",
        "            minimum=0,\n",
        "            maximum=50,\n",
        "            value=7.5,\n",
        "            step=0.1,\n",
        "        )\n",
        "        num_images = gr.Slider(\n",
        "            label=\"Number of images\",\n",
        "            minimum=1,\n",
        "            maximum=MAX_IMAGES,\n",
        "            value=min(4, MAX_IMAGES),\n",
        "            step=1,\n",
        "        )\n",
        "        save_images = gr.Checkbox(\n",
        "            label=f\"Save images to {'Google Drive' if USE_GOOGLE_DRIVE else 'local storage'}\",\n",
        "            value=False,\n",
        "            info=f\"Saves to: {OUTPUT_DIR}\",\n",
        "        )\n",
        "    \n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=[prompt],\n",
        "    )\n",
        "    \n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "        <div style=\"text-align: center; margin-top: 20px; font-size: 0.8rem; color: #666;\">\n",
        "            <p>Model: <a href=\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\" target=\"_blank\">stabilityai/stable-diffusion-xl-base-1.0</a></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    btn.click(\n",
        "        infer,\n",
        "        inputs=[prompt, negative, guidance_scale, style_selection, num_images, save_images],\n",
        "        outputs=[gallery],\n",
        "    )\n",
        "    prompt.submit(\n",
        "        infer,\n",
        "        inputs=[prompt, negative, guidance_scale, style_selection, num_images, save_images],\n",
        "        outputs=[gallery],\n",
        "    )\n",
        "\n",
        "print(\"Gradio interface built.\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "gradio-ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the app with a public URL\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "launch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
